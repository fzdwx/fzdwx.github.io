{"number":0,"title":"","body":"[#添加](https://github.com/fzdwx/fzdwx.github.io/discussions/4) \r\n\r\n","bodyHTML":"\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/fzdwx/fzdwx.github.io/discussions/4\" data-hovercard-type=\"discussion\" data-hovercard-url=\"/fzdwx/fzdwx.github.io/discussions/4/hovercard\"\u003e#添加\u003c/a\u003e\u003c/p\u003e","locked":false,"upvoteCount":0,"url":"https://github.com/fzdwx/fzdwx.github.io/discussions/4","createdAt":"0001-01-01T00:00:00Z","updatedAt":"0001-01-01T00:00:00Z","author":null,"comments":{"totalCount":5,"nodes":[{"body":"InnoDB 的索引模型:\r\n\r\n在 InnoDB 中，每一个索引都对应一颗 B+ 树，有下面的建表 SQL，id 与 k 都是索引列: \r\n\r\n```sql\r\ncreate table T(\r\nid int primary key, \r\nk int not null, \r\nname varchar(16),\r\nindex (k) \r\n)engine=InnoDB;\r\n```\r\n\r\n![image](https://github.com/fzdwx/fzdwx.github.io/assets/65269574/76da8d26-f9ba-4f81-8caf-cac848f97b4b)\r\n\r\n\r\n可以看出索引分为 主键索引 以及  非主键索引\r\n\r\n1. `主键索引`(聚簇索引的叶子节点存放了整行的数据,\r\n2. `非主建索引`(二级索引)的叶子节点存放的是主键的值\r\n\r\n基于主键索引和普通索引的查询有什么区别?\r\n\r\n- 如果是 `select * from t where id = 1` 使用主键索引则只需要查找 `ID` 索引树\r\n- 如果是 `select * from t where k = 6` 则需要先查找 `k` 索引树然后在到  `ID` 索引树中在查找. 这个过程就是 **回表**\r\n\r\n为什么推荐使用自增主键？\r\n\r\nB+树为了保证索引的有序性，在插入以及删除值的时候进行必要的维护.以上面这个图为例，如果插入新的行 ID 值为 700，则只需要在 R5 的记录后面插入一个新记录。如果新插入的 ID 值为 400，就相对麻烦了，需要逻辑上挪动后面的数据，空出位置。\r\n\r\n而更糟的情况是，如果 R5 所在的数据页已经满了，根据 B+ 树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为页分裂。在这种情况下，性能自然会受影响。\r\n\r\n而使用一个递增的主键就可以保证每次插入都是追加，写数据性能就会提高.\r\n\r\n[tags:#MySQL]\r\n","bodyHTML":"\u003cp dir=\"auto\"\u003eInnoDB 的索引模型:\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e在 InnoDB 中，每一个索引都对应一颗 B+ 树，有下面的建表 SQL，id 与 k 都是索引列:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-sql notranslate position-relative overflow-auto\" dir=\"auto\" data-snippet-clipboard-copy-content=\"create table T(\nid int primary key, \nk int not null, \nname varchar(16),\nindex (k) \n)engine=InnoDB;\"\u003e\u003cpre class=\"notranslate\"\u003e\u003cspan class=\"pl-k\"\u003ecreate\u003c/span\u003e \u003cspan class=\"pl-k\"\u003etable\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eT\u003c/span\u003e(\nid \u003cspan class=\"pl-k\"\u003eint\u003c/span\u003e \u003cspan class=\"pl-k\"\u003eprimary key\u003c/span\u003e, \nk \u003cspan class=\"pl-k\"\u003eint\u003c/span\u003e \u003cspan class=\"pl-k\"\u003enot null\u003c/span\u003e, \nname \u003cspan class=\"pl-k\"\u003evarchar\u003c/span\u003e(\u003cspan class=\"pl-c1\"\u003e16\u003c/span\u003e),\nindex (k) \n)engine\u003cspan class=\"pl-k\"\u003e=\u003c/span\u003eInnoDB;\u003c/pre\u003e\u003c/div\u003e\n\u003cp dir=\"auto\"\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/65269574/262654721-76da8d26-f9ba-4f81-8caf-cac848f97b4b.png\"\u003e\u003cimg src=\"https://user-images.githubusercontent.com/65269574/262654721-76da8d26-f9ba-4f81-8caf-cac848f97b4b.png\" alt=\"image\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e可以看出索引分为 主键索引 以及  非主键索引\u003c/p\u003e\n\u003col dir=\"auto\"\u003e\n\u003cli\u003e\u003ccode class=\"notranslate\"\u003e主键索引\u003c/code\u003e(聚簇索引的叶子节点存放了整行的数据,\u003c/li\u003e\n\u003cli\u003e\u003ccode class=\"notranslate\"\u003e非主建索引\u003c/code\u003e(二级索引)的叶子节点存放的是主键的值\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp dir=\"auto\"\u003e基于主键索引和普通索引的查询有什么区别?\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e如果是 \u003ccode class=\"notranslate\"\u003eselect * from t where id = 1\u003c/code\u003e 使用主键索引则只需要查找 \u003ccode class=\"notranslate\"\u003eID\u003c/code\u003e 索引树\u003c/li\u003e\n\u003cli\u003e如果是 \u003ccode class=\"notranslate\"\u003eselect * from t where k = 6\u003c/code\u003e 则需要先查找 \u003ccode class=\"notranslate\"\u003ek\u003c/code\u003e 索引树然后在到  \u003ccode class=\"notranslate\"\u003eID\u003c/code\u003e 索引树中在查找. 这个过程就是 \u003cstrong\u003e回表\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp dir=\"auto\"\u003e为什么推荐使用自增主键？\u003c/p\u003e\n\u003cp dir=\"auto\"\u003eB+树为了保证索引的有序性，在插入以及删除值的时候进行必要的维护.以上面这个图为例，如果插入新的行 ID 值为 700，则只需要在 R5 的记录后面插入一个新记录。如果新插入的 ID 值为 400，就相对麻烦了，需要逻辑上挪动后面的数据，空出位置。\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e而更糟的情况是，如果 R5 所在的数据页已经满了，根据 B+ 树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为页分裂。在这种情况下，性能自然会受影响。\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e而使用一个递增的主键就可以保证每次插入都是追加，写数据性能就会提高.\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e\u003c/p\u003e","upvoteCount":1,"url":"https://github.com/fzdwx/fzdwx.github.io/discussions/4#discussioncomment-6801616","authorAssociation":"OWNER","createdAt":"2023-08-23T11:31:36Z","updatedAt":"2023-08-23T11:31:37Z","author":{"login":"fzdwx","avatarUrl":"https://avatars.githubusercontent.com/u/65269574?u=c07fa94c7259b498e43da15c14378365ae96e7db\u0026v=4","url":"https://github.com/fzdwx","bio":"","email":"","company":"","location":"","name":"","twitterUsername":""},"reactionGroups":[{"content":"THUMBS_UP","reactors":{"totalCount":0}},{"content":"THUMBS_DOWN","reactors":{"totalCount":0}},{"content":"LAUGH","reactors":{"totalCount":0}},{"content":"HOORAY","reactors":{"totalCount":0}},{"content":"CONFUSED","reactors":{"totalCount":0}},{"content":"HEART","reactors":{"totalCount":0}},{"content":"ROCKET","reactors":{"totalCount":0}},{"content":"EYES","reactors":{"totalCount":0}}],"tags":["#MySQL"]},{"body":"事务之隔离性\r\n\r\n当数据库上有多个事务同时执行的时候，就可能出现脏读、不可重复读、幻读等问题，这就需要靠隔离级别来解决.\r\n\r\n隔离级别包括:\r\n\r\n1. 读未提交: 一个事务还没提交时，它的变更就能被其他事务看到\r\n    - 直接返回记录上的最新值\r\n2. 读提交: 一个事务提交后，它做的变更才会被其他事务看到\r\n    - 视图在每个 SQL 语句开始执行的时候创建的\r\n3. 可重复读: 一个事务执行过程中看到的数据，总是跟这个事务在启\r\n动是看到的数据是一致的，当然这个事务的变更也对其他事务不可见\r\n    - 在事务启动时创建视图, 整个事务都使用这个视图来访问数据\r\n4. 串行:  对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行\r\n    - 直接用加锁的方式来避免并行访问\r\n\r\n\r\nMySQL 默认隔离级别是 可重复读，Oracle 是 读提交.\r\n\r\n怎么实现事务隔离?\r\n\r\n1. 每条 SQL 执行后都会记录一条对应的回滚操作 undo log\r\n2. 不同时刻启动的事务都有不同的 视图\r\n\r\n这就会使得一条记录在系统中的同一时刻会有不同的版本，如果视图 A 要得到 1，就必须依次执行下面的所有回滚操作得到\r\n\r\n![image](https://github.com/fzdwx/fzdwx.github.io/assets/65269574/09107efb-92a6-439f-a87b-d047d3a56b3f)\r\n\r\n\r\n[tags:#MySQL]","bodyHTML":"\u003cp dir=\"auto\"\u003e事务之隔离性\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e当数据库上有多个事务同时执行的时候，就可能出现脏读、不可重复读、幻读等问题，这就需要靠隔离级别来解决.\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e隔离级别包括:\u003c/p\u003e\n\u003col dir=\"auto\"\u003e\n\u003cli\u003e读未提交: 一个事务还没提交时，它的变更就能被其他事务看到\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e直接返回记录上的最新值\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e读提交: 一个事务提交后，它做的变更才会被其他事务看到\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e视图在每个 SQL 语句开始执行的时候创建的\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e可重复读: 一个事务执行过程中看到的数据，总是跟这个事务在启\u003cbr\u003e\n动是看到的数据是一致的，当然这个事务的变更也对其他事务不可见\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e在事务启动时创建视图, 整个事务都使用这个视图来访问数据\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e串行:  对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e直接用加锁的方式来避免并行访问\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp dir=\"auto\"\u003eMySQL 默认隔离级别是 可重复读，Oracle 是 读提交.\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e怎么实现事务隔离?\u003c/p\u003e\n\u003col dir=\"auto\"\u003e\n\u003cli\u003e每条 SQL 执行后都会记录一条对应的回滚操作 undo log\u003c/li\u003e\n\u003cli\u003e不同时刻启动的事务都有不同的 视图\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp dir=\"auto\"\u003e这就会使得一条记录在系统中的同一时刻会有不同的版本，如果视图 A 要得到 1，就必须依次执行下面的所有回滚操作得到\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/65269574/262619809-09107efb-92a6-439f-a87b-d047d3a56b3f.png\"\u003e\u003cimg src=\"https://user-images.githubusercontent.com/65269574/262619809-09107efb-92a6-439f-a87b-d047d3a56b3f.png\" alt=\"image\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e\u003c/p\u003e","upvoteCount":1,"url":"https://github.com/fzdwx/fzdwx.github.io/discussions/4#discussioncomment-6800370","authorAssociation":"OWNER","createdAt":"2023-08-23T09:13:24Z","updatedAt":"2023-08-23T09:13:25Z","author":{"login":"fzdwx","avatarUrl":"https://avatars.githubusercontent.com/u/65269574?u=c07fa94c7259b498e43da15c14378365ae96e7db\u0026v=4","url":"https://github.com/fzdwx","bio":"","email":"","company":"","location":"","name":"","twitterUsername":""},"reactionGroups":[{"content":"THUMBS_UP","reactors":{"totalCount":0}},{"content":"THUMBS_DOWN","reactors":{"totalCount":0}},{"content":"LAUGH","reactors":{"totalCount":0}},{"content":"HOORAY","reactors":{"totalCount":0}},{"content":"CONFUSED","reactors":{"totalCount":0}},{"content":"HEART","reactors":{"totalCount":0}},{"content":"ROCKET","reactors":{"totalCount":0}},{"content":"EYES","reactors":{"totalCount":0}}],"tags":["#MySQL"]},{"body":"书籍收藏:\r\n\r\n1. DDIA(设计数据密集型应用程序)\r\n\t- [中文翻译](https://github.com/Vonng/ddia)\r\n\t- [逐章精读](https://github.com/DistSysCorp/ddia)\r\n2. Rust Atomics and Locks\r\n\t- [中文翻译](https://github.com/rustcc/Rust_Atomics_and_Locks)\r\n3. [深入架构原理与实践](https://github.com/isno/theByteBook)\r\n\r\n[tags:#book]","bodyHTML":"\u003cp dir=\"auto\"\u003e书籍收藏:\u003c/p\u003e\n\u003col dir=\"auto\"\u003e\n\u003cli\u003eDDIA(设计数据密集型应用程序)\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/Vonng/ddia\"\u003e中文翻译\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/DistSysCorp/ddia\"\u003e逐章精读\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eRust Atomics and Locks\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/rustcc/Rust_Atomics_and_Locks\"\u003e中文翻译\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/isno/theByteBook\"\u003e深入架构原理与实践\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp dir=\"auto\"\u003e\u003c/p\u003e","upvoteCount":1,"url":"https://github.com/fzdwx/fzdwx.github.io/discussions/4#discussioncomment-6779905","authorAssociation":"OWNER","createdAt":"2023-08-21T11:32:09Z","updatedAt":"2023-08-21T11:32:22Z","author":{"login":"fzdwx","avatarUrl":"https://avatars.githubusercontent.com/u/65269574?u=c07fa94c7259b498e43da15c14378365ae96e7db\u0026v=4","url":"https://github.com/fzdwx","bio":"","email":"","company":"","location":"","name":"","twitterUsername":""},"reactionGroups":[{"content":"THUMBS_UP","reactors":{"totalCount":0}},{"content":"THUMBS_DOWN","reactors":{"totalCount":0}},{"content":"LAUGH","reactors":{"totalCount":0}},{"content":"HOORAY","reactors":{"totalCount":0}},{"content":"CONFUSED","reactors":{"totalCount":0}},{"content":"HEART","reactors":{"totalCount":0}},{"content":"ROCKET","reactors":{"totalCount":0}},{"content":"EYES","reactors":{"totalCount":0}}],"tags":["#book"]},{"body":"一条更新 SQL 的执行流程:\r\n\r\n1. 总体流程和查询的 SQL 执行流程类似, 但更新流程涉及到两个重要的日志模块: redo log(重做日志), binlog(归档日志)\r\n2. 关键点是先写日志, 在写磁盘 —— InnoDB 会先把记录写道 redo log 里面并更新内存, 这个时候更新操作就算完成了, 后续会在适当的时候写入到磁盘中(比如系统比较空闲). \r\n\r\n重要的日志模块: redo log\r\n\r\nInnoDB 的 redo log 是固定大小的, 比如可以配置为一组 4 个文件, 每个文件的大小是 1GB, 即总容量是 4GB. 从头开始写, 写倒末尾就就又回到开头循环写:\r\n\r\n![image](https://github.com/fzdwx/fzdwx.github.io/assets/65269574/4907b5f2-8ff2-49e4-af00-d3a39dfd2822)\r\n\r\n1. `write pos` 是当前记录的位置, 一边写一边后移, 写到 3 号文件末尾就会到 0 号文件重新开始\r\n2. `check point` 是当前要擦除的位置, 同样是循环的, 擦除记录前要把记录更新到数据文件\r\n3. `write pos` 和 `check point` 之间的空间就是可以用来记录新的操作, 如果这两个值相等就表示不能继续写了, 得先写入一些数据到磁盘(`check point` 擦除).\r\n\r\n有了 redo log, InnoDB 可以保证即使数据库发生异常重启, 之前提交的记录都不会丢失 —— crach-safe\r\n\r\n重要的日志模块: binlog\r\n\r\nbinlog有两种模式，statement 格式的话是记sql语句， row格式会记录行的内容，记两条，更新前和更新后都有。\r\n\r\n1. binlog server 自带的而 redo log 是 InnoDB 独有的\r\n2. redo log 是物理日志, 记录了在某个数据页上做了什么修改, binglog 是逻辑日志, 记录的是语句的原始逻辑, 比如\"给 ID = 2 的这一行的 age 字段加 1\"\r\n3. redo log 是循环写, binglog 是追加的, 在文件到达一定大小会切换到下一个\r\n\r\n\r\n所以执行器和引擎执行更新 SQL 的流程:\r\n\r\n1. 执行器先找引擎取 ID = 2 的这一行, 假如 ID 为主键, 引擎就直接用树搜索找到这一行, 如果这一行所在的数据页本来就在内存中, 就直接返回, 否则就先从磁盘读入内存然后返回\r\n2. 执行器拿到引擎给的数据, 执行更新操作, 然后在调用引擎写入数据\r\n3. 引擎将这行数据更新到内存中, 同时将更新操作记录到 redo log 中, 此时 redo log 处于 `prepare` 状态. 然后告知执行器执行完成了, 随时可以提交事务\r\n4. 执行器生成这个操作的 binlog, 并把 binlog 写入磁盘\r\n5. 执行器调用引擎的提交事务接口, 引擎把刚刚写入的 redo log 改为 `commit` 状态, 更新完成\r\n\r\n![image](https://github.com/fzdwx/fzdwx.github.io/assets/65269574/f8d1bf3f-1053-4137-82f6-f4e5548e8e09)\r\n\r\n\r\n为什么需要两阶段提交?\r\n\r\n1. 如果在 prepare 阶段崩溃, 重启恢复后发现没有 commit 会回滚. 备份恢复, 发现没有这条记录的 binlog. 数据一致\r\n2. 如果在 commit 时崩溃, 重启恢复时满足 prepare 和 binlog 完整会自动 commit . 备份恢复时有binlog 数据一致\r\n\r\n[tags:#MySQL]","bodyHTML":"\u003cp dir=\"auto\"\u003e一条更新 SQL 的执行流程:\u003c/p\u003e\n\u003col dir=\"auto\"\u003e\n\u003cli\u003e总体流程和查询的 SQL 执行流程类似, 但更新流程涉及到两个重要的日志模块: redo log(重做日志), binlog(归档日志)\u003c/li\u003e\n\u003cli\u003e关键点是先写日志, 在写磁盘 —— InnoDB 会先把记录写道 redo log 里面并更新内存, 这个时候更新操作就算完成了, 后续会在适当的时候写入到磁盘中(比如系统比较空闲).\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp dir=\"auto\"\u003e重要的日志模块: redo log\u003c/p\u003e\n\u003cp dir=\"auto\"\u003eInnoDB 的 redo log 是固定大小的, 比如可以配置为一组 4 个文件, 每个文件的大小是 1GB, 即总容量是 4GB. 从头开始写, 写倒末尾就就又回到开头循环写:\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/65269574/259082685-4907b5f2-8ff2-49e4-af00-d3a39dfd2822.png\"\u003e\u003cimg src=\"https://user-images.githubusercontent.com/65269574/259082685-4907b5f2-8ff2-49e4-af00-d3a39dfd2822.png\" alt=\"image\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003col dir=\"auto\"\u003e\n\u003cli\u003e\u003ccode class=\"notranslate\"\u003ewrite pos\u003c/code\u003e 是当前记录的位置, 一边写一边后移, 写到 3 号文件末尾就会到 0 号文件重新开始\u003c/li\u003e\n\u003cli\u003e\u003ccode class=\"notranslate\"\u003echeck point\u003c/code\u003e 是当前要擦除的位置, 同样是循环的, 擦除记录前要把记录更新到数据文件\u003c/li\u003e\n\u003cli\u003e\u003ccode class=\"notranslate\"\u003ewrite pos\u003c/code\u003e 和 \u003ccode class=\"notranslate\"\u003echeck point\u003c/code\u003e 之间的空间就是可以用来记录新的操作, 如果这两个值相等就表示不能继续写了, 得先写入一些数据到磁盘(\u003ccode class=\"notranslate\"\u003echeck point\u003c/code\u003e 擦除).\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp dir=\"auto\"\u003e有了 redo log, InnoDB 可以保证即使数据库发生异常重启, 之前提交的记录都不会丢失 —— crach-safe\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e重要的日志模块: binlog\u003c/p\u003e\n\u003cp dir=\"auto\"\u003ebinlog有两种模式，statement 格式的话是记sql语句， row格式会记录行的内容，记两条，更新前和更新后都有。\u003c/p\u003e\n\u003col dir=\"auto\"\u003e\n\u003cli\u003ebinlog server 自带的而 redo log 是 InnoDB 独有的\u003c/li\u003e\n\u003cli\u003eredo log 是物理日志, 记录了在某个数据页上做了什么修改, binglog 是逻辑日志, 记录的是语句的原始逻辑, 比如\"给 ID = 2 的这一行的 age 字段加 1\"\u003c/li\u003e\n\u003cli\u003eredo log 是循环写, binglog 是追加的, 在文件到达一定大小会切换到下一个\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp dir=\"auto\"\u003e所以执行器和引擎执行更新 SQL 的流程:\u003c/p\u003e\n\u003col dir=\"auto\"\u003e\n\u003cli\u003e执行器先找引擎取 ID = 2 的这一行, 假如 ID 为主键, 引擎就直接用树搜索找到这一行, 如果这一行所在的数据页本来就在内存中, 就直接返回, 否则就先从磁盘读入内存然后返回\u003c/li\u003e\n\u003cli\u003e执行器拿到引擎给的数据, 执行更新操作, 然后在调用引擎写入数据\u003c/li\u003e\n\u003cli\u003e引擎将这行数据更新到内存中, 同时将更新操作记录到 redo log 中, 此时 redo log 处于 \u003ccode class=\"notranslate\"\u003eprepare\u003c/code\u003e 状态. 然后告知执行器执行完成了, 随时可以提交事务\u003c/li\u003e\n\u003cli\u003e执行器生成这个操作的 binlog, 并把 binlog 写入磁盘\u003c/li\u003e\n\u003cli\u003e执行器调用引擎的提交事务接口, 引擎把刚刚写入的 redo log 改为 \u003ccode class=\"notranslate\"\u003ecommit\u003c/code\u003e 状态, 更新完成\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp dir=\"auto\"\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/65269574/259111370-f8d1bf3f-1053-4137-82f6-f4e5548e8e09.png\"\u003e\u003cimg src=\"https://user-images.githubusercontent.com/65269574/259111370-f8d1bf3f-1053-4137-82f6-f4e5548e8e09.png\" alt=\"image\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e为什么需要两阶段提交?\u003c/p\u003e\n\u003col dir=\"auto\"\u003e\n\u003cli\u003e如果在 prepare 阶段崩溃, 重启恢复后发现没有 commit 会回滚. 备份恢复, 发现没有这条记录的 binlog. 数据一致\u003c/li\u003e\n\u003cli\u003e如果在 commit 时崩溃, 重启恢复时满足 prepare 和 binlog 完整会自动 commit . 备份恢复时有binlog 数据一致\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp dir=\"auto\"\u003e\u003c/p\u003e","upvoteCount":1,"url":"https://github.com/fzdwx/fzdwx.github.io/discussions/4#discussioncomment-6668339","authorAssociation":"OWNER","createdAt":"2023-08-08T11:26:39Z","updatedAt":"2023-08-08T13:18:35Z","author":{"login":"fzdwx","avatarUrl":"https://avatars.githubusercontent.com/u/65269574?u=c07fa94c7259b498e43da15c14378365ae96e7db\u0026v=4","url":"https://github.com/fzdwx","bio":"","email":"","company":"","location":"","name":"","twitterUsername":""},"reactionGroups":[{"content":"THUMBS_UP","reactors":{"totalCount":0}},{"content":"THUMBS_DOWN","reactors":{"totalCount":0}},{"content":"LAUGH","reactors":{"totalCount":0}},{"content":"HOORAY","reactors":{"totalCount":0}},{"content":"CONFUSED","reactors":{"totalCount":0}},{"content":"HEART","reactors":{"totalCount":0}},{"content":"ROCKET","reactors":{"totalCount":0}},{"content":"EYES","reactors":{"totalCount":0}}],"tags":["#MySQL"]},{"body":"一条查询 SQL 的执行过程:\r\n\r\n1.  client 与连接器建立连接，连接器确认 client 认证信息以及权限信息\r\n2. 分析器进行词法分析(select, where, update, group by...), 然后进行语法分析\r\n3. 优化器选择索引生成执行计划\r\n4. 执行器调用存储引擎的读写接口进行数据查询\r\n\r\n![image](https://github.com/fzdwx/fzdwx.github.io/assets/65269574/645e5834-d596-4c9e-b4d7-cb10365d60a3)\r\n\r\n\r\n\r\n[tags:#MySQL]","bodyHTML":"\u003cp dir=\"auto\"\u003e一条查询 SQL 的执行过程:\u003c/p\u003e\n\u003col dir=\"auto\"\u003e\n\u003cli\u003eclient 与连接器建立连接，连接器确认 client 认证信息以及权限信息\u003c/li\u003e\n\u003cli\u003e分析器进行词法分析(select, where, update, group by...), 然后进行语法分析\u003c/li\u003e\n\u003cli\u003e优化器选择索引生成执行计划\u003c/li\u003e\n\u003cli\u003e执行器调用存储引擎的读写接口进行数据查询\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp dir=\"auto\"\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/65269574/258571472-645e5834-d596-4c9e-b4d7-cb10365d60a3.png\"\u003e\u003cimg src=\"https://user-images.githubusercontent.com/65269574/258571472-645e5834-d596-4c9e-b4d7-cb10365d60a3.png\" alt=\"image\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e\u003c/p\u003e","upvoteCount":1,"url":"https://github.com/fzdwx/fzdwx.github.io/discussions/4#discussioncomment-6643890","authorAssociation":"OWNER","createdAt":"2023-08-05T05:12:23Z","updatedAt":"2023-08-05T11:59:50Z","author":{"login":"fzdwx","avatarUrl":"https://avatars.githubusercontent.com/u/65269574?u=c07fa94c7259b498e43da15c14378365ae96e7db\u0026v=4","url":"https://github.com/fzdwx","bio":"","email":"","company":"","location":"","name":"","twitterUsername":""},"reactionGroups":[{"content":"THUMBS_UP","reactors":{"totalCount":1}},{"content":"THUMBS_DOWN","reactors":{"totalCount":0}},{"content":"LAUGH","reactors":{"totalCount":0}},{"content":"HOORAY","reactors":{"totalCount":0}},{"content":"CONFUSED","reactors":{"totalCount":0}},{"content":"HEART","reactors":{"totalCount":0}},{"content":"ROCKET","reactors":{"totalCount":0}},{"content":"EYES","reactors":{"totalCount":0}}],"tags":["#MySQL"]}],"pageInfo":{"hasNextPage":false,"endCursor":"Y3Vyc29yOnYyOpK5MjAyMy0wOC0yM1QxOTozMTozNiswODowMM4AZ8jQ"}},"reactionGroups":null}
